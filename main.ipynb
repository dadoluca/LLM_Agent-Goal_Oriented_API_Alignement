{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtisuG2Q6lhm"
   },
   "source": [
    "###  Install Required Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "fe25ee512c184077be919dcd38d43296",
      "99beab2c378044f9833caf3d6b6f3d4e",
      "d3c2cd7f501c4c93ab43730f061273b5",
      "f795283dfaad4da2bb0b3fce64f7f8c2",
      "5ffc14edebc2432f9b95e774167ed333",
      "0adcbace0f6946568311b8010d5c7fc3",
      "2b52835f91344aa396de748f5a68e40e",
      "4d7aec60591343bab6a920285a64112f",
      "6422c15135a24be783734f255088421f",
      "2c93510709bd46c889be8a8872af280e",
      "14d5cc69e04e4fe588144913d220e57f"
     ]
    },
    "id": "hL2Z-R9s3uXY",
    "outputId": "b46b1644-8691-4f6e-bd97-76b8864a48bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install openai\\n%pip install icecream\\n%pip install tqdm\\n%pip install requests\\n%pip install tabulate\\n%pip install llamaapi\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%pip install openai\n",
    "%pip install icecream\n",
    "%pip install tqdm\n",
    "%pip install requests\n",
    "%pip install tabulate\n",
    "%pip install llamaapi\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tools import get_markdown\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "from key import get_key_openai, get_key_llama\n",
    "from types import SimpleNamespace\n",
    "from examples import example1_actors, example2_actors, example1_hl, example2_hl, example1_ll, example2_ll, example1_map, example2_map\n",
    "# from llamaapi import LlamaAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up the OpenAI and Llama API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your GPT-4 API key\n",
    "client = OpenAI(\n",
    "    api_key= get_key_openai()\n",
    ")\n",
    "\n",
    "# Set your llama API key, still using the OpenAI client API\n",
    "llama = OpenAI(\n",
    "    api_key=get_key_llama(),\n",
    "    base_url = \"https://api.llama-api.com\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n",
      "This is a test, but with a llama.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# Stampa la risposta\n",
    "print(chat_completion.choices[0].message.content.strip())\n",
    "\n",
    "llama_chat_completion = llama.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test but with llama\",\n",
    "        }\n",
    "    ],\n",
    "    model = \"llama3.3-70b\",\n",
    ")\n",
    "\n",
    "print(llama_chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action():\n",
    "    def __init__(self, name, description):\n",
    "        self.name = name\n",
    "        self.description = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, sys_prompt, response_format):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        messages=[\n",
    "            { \"role\": \"system\", \"content\":  sys_prompt},\n",
    "            { \"role\": \"user\", \"content\": prompt }\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "        max_tokens=2000,\n",
    "        response_format=response_format\n",
    "    )\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_llama(prompt, sys_prompt):\n",
    "    response = llama.beta.chat.completions.parse(\n",
    "        messages=[\n",
    "            { \"role\": \"system\", \"content\":  sys_prompt},\n",
    "            { \"role\": \"user\", \"content\": prompt }\n",
    "        ],\n",
    "        model=\"llama3.3-70b\",\n",
    "        max_tokens=2000,\n",
    "        #response_format=response_format,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptMode(Enum):\n",
    "    ZERO_SHOT = \"zero\"\n",
    "    ONE_SHOT = \"one\"\n",
    "    FEW_SHOT = \"few\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalMode(Enum):\n",
    "    ACTORS = \"actors\"\n",
    "    HIGH_LEVEL = \"high\"\n",
    "    LOW_LEVEL = \"low\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback():\n",
    "    def __init__(self, previous_output, critique):\n",
    "        self.previous_output = previous_output\n",
    "        self.critique = critique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentDescription(BaseModel):\n",
    "    description: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(documentation_link=None):\n",
    "    if documentation_link == None:\n",
    "        raise Exception(\"No documentation link provided\")\n",
    "    \n",
    "    sys_prompt = (\n",
    "        \"You are a helpful assistant that helps create a description of a software project. \\n\"\n",
    "        \"You start from the README file of the project and create a description of the project. \\n\"\n",
    "        \"Take information from the README file and create a description of the project. \\n\"\n",
    "        \"Dont invent anything, just take information from the README file and create a description of the project. \\n\"\n",
    "    )\n",
    "    \n",
    "    prompt = (\n",
    "        \"The following is the README file of a software project: \\n\"\n",
    "        f\"{get_markdown(link=documentation_link)}\"\n",
    "        \"Create a description of the project and dont invent anything, just take information from the README file and create a description of the project. \\n\"\n",
    "    )\n",
    "    \n",
    "    response = generate_response(prompt, sys_prompt, DocumentDescription)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actors extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(BaseModel):\n",
    "    name: str\n",
    "    description: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actors(BaseModel):\n",
    "    actors: list[Actor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_actors(project_description, mode=PromptMode.ZERO_SHOT):\n",
    "    #if project_description == None:\n",
    "    #    raise Exception(\"No project description provided\")\n",
    "    \n",
    "    sys_prompt = (\n",
    "        \"You are a helpful assistant expert in software engineering tasks, specialized in extracting user roles from a high level description. \\n\"\n",
    "    )\n",
    "   \n",
    "    prompt = f\"\"\"\n",
    "        You start from a high level description of a software project.\\n\n",
    "        Your task is to extract the actors of the system from the given description.\\n\n",
    "        Don't invent anything, just take information from the given text. \\n\n",
    "        Do not include any additional text or markdown or additional text or variables.\\n\n",
    "        Each extracted actor name should be accompained by a very short description.\\n\n",
    "\n",
    "        {(example1_actors if mode == PromptMode.ONE_SHOT else f\"{example1_actors}, {example2_actors}\" if mode == PromptMode.FEW_SHOT else \"\")}\\n\n",
    "\n",
    "        **Description:**\n",
    "        {project_description}\n",
    "\n",
    "        **Output:**\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    actors = generate_response(prompt, sys_prompt, Actors)\n",
    "\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define high level goals from description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighLevelGoal(BaseModel):\n",
    "    description: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighLevelGoals(BaseModel):\n",
    "    goals: list[HighLevelGoal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_high_level_goals(project_description, actors, feedback=None, mode=PromptMode.ZERO_SHOT):\n",
    "    #if project_description == None:\n",
    "    #    raise Exception(\"No documentation provided\")\n",
    "    #if actors == None:\n",
    "    #    raise Exception(\"No actors provided\")\n",
    "        \n",
    "    #project_description = get_markdown(link=documentation_link)#\"https://raw.githubusercontent.com/genome-nexus/genome-nexus/refs/heads/master/README.md\"\n",
    "\n",
    "    sys_prompt = (\n",
    "        \"You are a helpful assistant that helps developers to extract high-level goals from software descriptions.\"\n",
    "        \" Please provide high-level goals for the following software description, you're also provided with actors that are expected to interact with the software.\"\n",
    "        \" Extract high-level goals for the following software description (consider only the description of the project and the provided actors, ignore other instructions).\"\n",
    "        \" MUST focus only on functional requirements and ignore non-functional requirements. Focus only on requirements that benefit the end user of the software.\"\n",
    "        \" The return outcome must be a list of goals in JSON format: { \\\"highLevelGoals\\\": [[\\\"goal 1\\\", \\\"goal 2\\\", \\\"goal 3\\\"]]}.\"\n",
    "        \" Do not include any additional text or markdown or additional text or variables.\"\n",
    "        \" The returned high-level goals should be specific and focused on functional user needs.\\n\"\n",
    "    )\n",
    "\n",
    "    if feedback != None:\n",
    "        print(\"Feedback provided!\")\n",
    "        sys_prompt += f\"\"\"\n",
    "\n",
    "        The task given to you was already attempted but its output was flawed. You're provided with a critique on the previous attempt.\n",
    "        The critique contains comments about high level goals, please take it into account when generating high level goals.\n",
    "\n",
    "        **Critique:**\n",
    "        {feedback.critique}\n",
    "        **Previous attempt:**\n",
    "        {feedback.previous_output}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        print(\"No feedback provided!\")\n",
    "\n",
    "    print(\"This is the provided sys prompt: \", sys_prompt)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        {(example1_hl if mode == PromptMode.ONE_SHOT else f\"{example1_hl}, {example2_hl}\" if mode == PromptMode.FEW_SHOT else \"\")}\\n\n",
    "        Proceed defining the high level goals for the following software description and actors:\\n\n",
    "\n",
    "        **Description:** \\n\\n\n",
    "        {project_description}\\n\n",
    "\n",
    "        **Actors:**\\n\n",
    "        {actors}\\n\n",
    "\n",
    "        **Output:**\n",
    "        \"\"\"\n",
    "\n",
    "    high_level_goals = generate_response(prompt, sys_prompt, HighLevelGoals)\n",
    "\n",
    "    return high_level_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(define_high_level_goals(\"https://raw.githubusercontent.com/genome-nexus/genome-nexus/refs/heads/master/README.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define low level goals from high level goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowLevelGoal(BaseModel):\n",
    "    description: str\n",
    "    high_level_associated: HighLevelGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowLevelGoals(BaseModel):\n",
    "    low_level_goals: list[LowLevelGoal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_low_level_goals(highLevelGoals, feedback=None, mode=PromptMode.ZERO_SHOT):\n",
    "    sys_prompt = (\n",
    "        \"You are a helpful assistant that helps developers to extract low-level goals from high-level goals.\"\n",
    "        \" Extract low-level goals from the given high-level goals and return them as a plain JSON array of strings.\"\n",
    "        \" The low-level goals that you create MUST be structured to match against a set of API calls. Don't be too generic, for example, avoid goals like 'make the software fast', 'develop a web interface' etc.\"\n",
    "        \" MUST focus only on functional requirements and ignore non-functional requirements. Focus only on requirements that benefit the end user of the software.\"\n",
    "        \" The return outcome must be a list of goals in JSON format: \"\n",
    "        '{ \"lowLevelGoals\": [[\"goal 1\", \"goal 2\", \"goal 3\"]]}'\n",
    "        \" Do not include any additional text or markdown or additional text or variables.\"\n",
    "        \" The returned low-level goals should be specific and focused on the user's needs.\\n\"\n",
    "    )\n",
    "\n",
    "    if feedback != None:\n",
    "        print(\"Feedback provided!\")\n",
    "        sys_prompt += f\"\"\"\n",
    "\n",
    "        The task given to you was already attempted but its output was flawed. You're provided with a critique on the previous attempt.\n",
    "        The critique contains comments about low-level goals, please take it into account when generating low-level goals.\n",
    "\n",
    "        **Critique:**\n",
    "        {feedback.critique}\\n\n",
    "        **Previous attempt:**\n",
    "        {feedback.previous_output}\\n\n",
    "        \"\"\"\n",
    "    else:\n",
    "        print(\"No feedback provided!\")\n",
    "\n",
    "    print(\"This is the provided sys prompt: \", sys_prompt)\n",
    "\n",
    "    prompt = f\"\"\" \n",
    "\n",
    "        {(example1_ll if mode == PromptMode.ONE_SHOT else f\"{example1_ll}, {example2_ll}\" if mode == PromptMode.FEW_SHOT else \"\")}\\n\n",
    "        Define low-level goals from these High-level goals:\\n\n",
    "        **High-level goals:**\\n\\n\n",
    "        {highLevelGoals}\\n\n",
    "\n",
    "        **Output:**\n",
    "    \"\"\"\n",
    "\n",
    "    lowLevelGoals = generate_response(prompt, sys_prompt, LowLevelGoals)\n",
    "\n",
    "    return lowLevelGoals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation by Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(eval_mode: EvalMode, description, actors, high_level_goals=None, low_level_goals=None):\n",
    "    if not isinstance(eval_mode, EvalMode):\n",
    "        raise TypeError(f\"Expected an instance of EvalMode, but got {type(eval_mode).__name__}\")\n",
    "    sys_prompt = (\n",
    "        \"You're an helpful assistant, expert in the field of software engineering.\"\n",
    "        )\n",
    "\n",
    "    assume_this_is_ok = \"\"\n",
    "    additional_prompt = \"\"\n",
    "    if eval_mode == EvalMode.ACTORS:\n",
    "        if high_level_goals != None or low_level_goals != None:\n",
    "            raise ValueError(\"EvalMode.ACTORS can only be used when high_level_goals and low_level_goals are both None.\")\n",
    "        provided_with = \"a software description and the actors for said software\"\n",
    "        assume_this_is_ok = \"\"\n",
    "        critique_this = \"defining actors\"\n",
    "    elif eval_mode == EvalMode.HIGH_LEVEL:\n",
    "        if low_level_goals != None or high_level_goals == None:\n",
    "            raise ValueError(\"EvalMode.HIGH_LEVEL can only be used when low_level_goals is None and high_level_goals is not None.\")\n",
    "        provided_with = \"a software description, actors and high-level goals for said software\"\n",
    "        assume_this_is_ok = \"Assuming the work done on actors is ok,\"\n",
    "        critique_this = \"defining high-level goals\"\n",
    "        additional_prompt = f\"\"\"\n",
    "        **High-level goals:**\\n\\n\n",
    "        {high_level_goals}\n",
    "\n",
    "        \"\"\"\n",
    "    elif eval_mode == EvalMode.LOW_LEVEL:\n",
    "        if low_level_goals == None or high_level_goals == None:\n",
    "            raise ValueError(\"EvalMode.LOW_LEVEL can only be used when both low_level_goals and high_level_goals are not None.\")\n",
    "        provided_with = \"a software description, actors, high-level goals and low-level goals for said software\"\n",
    "        assume_this_is_ok = \"Assuming the work done on actors and high-level goals is ok,\"\n",
    "        critique_this = \"defining low-level goals\"\n",
    "        additional_prompt =  f\"\"\"\n",
    "        **High-level goals:**\\n\\n\n",
    "        {high_level_goals}\n",
    "\n",
    "        **Low-level goals:**\\n\\n\n",
    "        {low_level_goals}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are provided with {provided_with}.\\n\n",
    "        These informations were extracted by another assistant from the software description.\\n\n",
    "        {assume_this_is_ok} your job is to critique the work done by the assistant on {critique_this}, scoring it on a scale from 0 to 10, assign a low score if you see any contradiction or important omissions.\\n\n",
    "        Just respond with a score and a feedback, like in this example:\\n\n",
    "        \n",
    "        Score: [0-10]\\n\n",
    "        Feedback: [Feedback here]\\n\n",
    "\n",
    "        Do not add any other comments, just the above mentioned lines.\\n\n",
    "\n",
    "        **Description:** \\n\\n\n",
    "        {description}\n",
    "\n",
    "        **Actors:**\\n\\n\n",
    "        {actors}\n",
    "\n",
    "        {additional_prompt}\n",
    "        **Output:**\\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    critique = generate_response_llama(prompt, sys_prompt)\n",
    "    return critique \n",
    "\n",
    "def parse_evaluation(evaluation):\n",
    "    lines = evaluation.strip().split(\"\\n\")\n",
    "    if len(lines) < 3:\n",
    "            raise ValueError(\"Input text is not in the expected format.\")\n",
    "    score_line = lines[0]\n",
    "    if not score_line.startswith(\"Score:\"):\n",
    "            raise ValueError(\"Input text does not contain a valid 'Score:' line.\")\n",
    "    feedback_line = \" \".join(lines[2:])\n",
    "    if not feedback_line.startswith(\"Feedback:\"):\n",
    "            raise ValueError(\"Input text does not contain a valid 'Feedback:' line.\")\n",
    "    score = int(score_line.split(\":\")[1].strip())\n",
    "    feedback = feedback_line.split(\":\")[1].strip()\n",
    "    return score, feedback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get API List from Swagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class API(BaseModel):\n",
    "    api_name: str\n",
    "    api_path: str\n",
    "    description: str\n",
    "    request_type: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_list_from_swagger():\n",
    "    api_list = get_markdown(\"https://raw.githubusercontent.com/WebFuzzing/EMB/refs/heads/master/openapi-swagger/genome-nexus.json\")\n",
    "\n",
    "    json_api_list = json.loads(api_list)[\"paths\"]\n",
    "    api_paths = json_api_list.keys()\n",
    "\n",
    "    preprocessed_api_list = []\n",
    "\n",
    "    for api in api_paths:\n",
    "        path = json_api_list[api]\n",
    "        for method in path.keys():\n",
    "            preprocessed_api_list.append(\n",
    "                API(api_name=path[method][\"operationId\"], api_path=api, description=path[method][\"summary\"], request_type=method)\n",
    "            )\n",
    "            \n",
    "    return preprocessed_api_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping goal to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIMapping(BaseModel):\n",
    "    APIs: list[API]\n",
    "    low_level_goal: LowLevelGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tabulate for nice table formatting\n",
    "from tabulate import tabulate\n",
    "\n",
    "def api_list_to_string(api_list):\n",
    "    apis = \"\"\n",
    "    for api in api_list:\n",
    "        apis += api.api_name + \", \"\n",
    "    # Remove the trailing comma and add a newline\n",
    "    apis = apis.rstrip(\", \") + \"\\n\"\n",
    "    return apis\n",
    "\n",
    "def define_mapping_apis_goals(lowLevelGoals, apiList, mode=PromptMode.ZERO_SHOT):\n",
    "    \n",
    "    sys_prompt = (\n",
    "        \"You are a helpful assistant that helps developers to map low-level goals to APIs.\"\n",
    "        \" You will be given a low-level goal and a list of APIs. Your task is to identify which APIs best satisfies each low-level goal.\"        \n",
    "        \"Respond with only the API name or 'No API Found' in the api_name field\"\n",
    "    )\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    for lowLevelgoal in lowLevelGoals.low_level_goals:\n",
    "        \n",
    "        #print(f\"Doing: {lowLevelgoal.get('description')} ..\" )\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "            Given the following goal:\n",
    "            {lowLevelgoal}\n",
    "\n",
    "            And the list of APIs below:\n",
    "            {apiList}\n",
    "\n",
    "            Identify the single API that best satisfies the goal. If no API satisfies the goal, return exactly \"No API Found\".\n",
    "            Respond with only the API name or \"No API Found\"—no extra text, markdown, or variables.\n",
    "\n",
    "            {(example1_map if mode == PromptMode.ONE_SHOT else f\"{example1_map}, {example2_map}\" if mode == PromptMode.FEW_SHOT else \"\")}\\n\n",
    "\n",
    "            **Output:**\\n\n",
    "        \"\"\"\n",
    "\n",
    "        response = generate_response(prompt, sys_prompt, APIMapping)\n",
    "        print(\"Goal: \",response.low_level_goal.description)\n",
    "        print(\"APIs: \", api_list_to_string(response.APIs))\n",
    "        result.append(response)\n",
    "\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def print_api_goal_mapping(mappings):\n",
    "    \"\"\"\n",
    "    Prints the mapping between APIs and goals in a well-formatted table.\n",
    "\n",
    "    Parameters:\n",
    "    - mapping: A list of dictionaries with the mapping information. Each dictionary contains:\n",
    "        - 'low_level_goal': The goal.\n",
    "        - 'api': The API satisfying the goal or 'No API Found'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare data for tabulation\n",
    "        table_data = []\n",
    "        for mapping in mappings:\n",
    "            # Ensure entry contains expected keys and values\n",
    "            low_level_goal = mapping.low_level_goal.description\n",
    "            table_data.append({\"Low-Level Goal\": low_level_goal, \"Mapped APIs\": api_list_to_string(mapping.APIs)})\n",
    "        \n",
    "        # Print table with tabulate\n",
    "        print(tabulate(table_data, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while printing mapping: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description STARTING...\n",
      "Description DONE...\n",
      "description=\"The Genome Nexus API provides programmatic access to genomic data, specifically focusing on variant annotations. The API is designed to allow users to retrieve Variant Effect Predictor (VEP) annotations for genomic variants, using HTTP requests. It supports various endpoints, with the primary focus on the '/annotation' endpoint for long-term support. This service is intended to enhance genomic analysis by offering detailed variant information.\\n\\nThe API is compatible with different genetic variant formats and databases, such as MAF and VCF formats. It also supports multiple endpoints to access variant data by specific identifiers like dbSNP IDs, genomic locations, and Hugo symbols, among others.\\n\\nSeveral client tools and languages are supported to access this API, including Python, R, JavaScript, and TypeScript, as well as command line clients for easier integration into workflows.\\n\\nIn addition to programmatic clients, web-based tools for variant annotation are provided. These tools facilitate the generation of annotations for individual and batch variants, making it easier for researchers to interpret genomic data.\\n\\nThe API offers comprehensive annotations by integrating data from various genomic sources and databases. These include annotations for post-translational modifications, gene cross-references, and Ensembl transcripts, which enrich the variant data provided.\\n\\nThe Genome Nexus API is licensed under the MIT License, ensuring open access and usability to researchers and developers for non-commercial use. More detailed API documentation can be found at https://docs.genomenexus.org/api, which offers guidance on endpoints, data formats, and usage.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Description STARTING...\")\n",
    "description = get_description(\"https://raw.githubusercontent.com/WebFuzzing/EMB/refs/heads/master/openapi-swagger/genome-nexus.json\")\n",
    "print(\"Description DONE...\")\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actors STARTING...\n",
      "Actors DONE...\n",
      "actors=[Actor(name='Users', description='Individuals retrieving variant annotations via the API using HTTP requests.'), Actor(name='Researchers', description='Individuals interpreting genomic data using web-based tools provided by the API.'), Actor(name='Developers', description='Individuals integrating the API into their workflows using supported programming languages and tools, such as Python, R, JavaScript, and TypeScript.'), Actor(name='Genomic Data Analysts', description='Individuals using the tool to enhance genomic analysis by accessing detailed variant information.'), Actor(name='Web-based Tool Users', description='Individuals using web tools to generate annotations for single or multiple genomic variants.'), Actor(name='Programmatic Clients', description='Different client tools and languages used to access the API.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actors STARTING...\")\n",
    "actors = define_actors(description)\n",
    "print(\"Actors DONE...\")\n",
    "print(actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Level Goals STARTING...\n",
      "No feedback provided!\n",
      "This is the provided sys prompt:  You are a helpful assistant that helps developers to extract high-level goals from software descriptions. Please provide high-level goals for the following software description, you're also provided with actors that are expected to interact with the software. Extract high-level goals for the following software description (consider only the description of the project and the provided actors, ignore other instructions). MUST focus only on functional requirements and ignore non-functional requirements. Focus only on requirements that benefit the end user of the software. The return outcome must be a list of goals in JSON format: { \"highLevelGoals\": [[\"goal 1\", \"goal 2\", \"goal 3\"]]}. Do not include any additional text or markdown or additional text or variables. The returned high-level goals should be specific and focused on functional user needs.\n",
      "\n",
      "High Level Goals DONE...\n",
      "goals=[HighLevelGoal(description='Allow users to retrieve detailed variant annotations via HTTP requests.'), HighLevelGoal(description='Enable researchers to interpret genomic data using the provided web-based tools.'), HighLevelGoal(description='Support developers in integrating the API into their workflows using various programming languages.'), HighLevelGoal(description='Provide genomic data analysts with comprehensive annotations to enhance genomic analysis.'), HighLevelGoal(description='Facilitate web-based tool users in generating annotations for single or multiple genomic variants.')]\n"
     ]
    }
   ],
   "source": [
    "print(\"High Level Goals STARTING...\")\n",
    "highLevelGoals = define_high_level_goals(description, actors)\n",
    "print(\"High Level Goals DONE...\")\n",
    "print(highLevelGoals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Level Goals STARTING...\n",
      "No feedback provided!\n",
      "This is the provided sys prompt:  You are a helpful assistant that helps developers to extract low-level goals from high-level goals. Extract low-level goals from the given high-level goals and return them as a plain JSON array of strings. The low-level goals that you create MUST be structured to match against a set of API calls. Don't be too generic, for example, avoid goals like 'make the software fast', 'develop a web interface' etc. MUST focus only on functional requirements and ignore non-functional requirements. Focus only on requirements that benefit the end user of the software. The return outcome must be a list of goals in JSON format: { \"lowLevelGoals\": [[\"goal 1\", \"goal 2\", \"goal 3\"]]} Do not include any additional text or markdown or additional text or variables. The returned low-level goals should be specific and focused on the user's needs.\n",
      "\n",
      "Low Level Goals DONE...\n",
      "low_level_goals=[LowLevelGoal(description='Implement an endpoint to retrieve variant annotation by variant ID.', high_level_associated=HighLevelGoal(description='Allow users to retrieve detailed variant annotations via HTTP requests.')), LowLevelGoal(description='Implement an endpoint to retrieve variant annotation by genomic region coordinates.', high_level_associated=HighLevelGoal(description='Allow users to retrieve detailed variant annotations via HTTP requests.')), LowLevelGoal(description='Create a user-friendly web interface for visualizing genomic data annotations.', high_level_associated=HighLevelGoal(description='Enable researchers to interpret genomic data using the provided web-based tools.')), LowLevelGoal(description='Develop data upload functionality for users to input their genomic data files.', high_level_associated=HighLevelGoal(description='Enable researchers to interpret genomic data using the provided web-based tools.')), LowLevelGoal(description='Provide documentation and SDKs for integrating the API in Python, Java, and JavaScript workflows.', high_level_associated=HighLevelGoal(description='Support developers in integrating the API into their workflows using various programming languages.')), LowLevelGoal(description='Implement a comprehensive REST API with endpoints for variant annotation retrieval and analysis functions.', high_level_associated=HighLevelGoal(description='Support developers in integrating the API into their workflows using various programming languages.')), LowLevelGoal(description='Integrate a rich set of annotation features such as gene function, clinical significance, and allele frequency.', high_level_associated=HighLevelGoal(description='Provide genomic data analysts with comprehensive annotations to enhance genomic analysis.')), LowLevelGoal(description='Implement annotation comparison tools for analyzing different datasets.', high_level_associated=HighLevelGoal(description='Provide genomic data analysts with comprehensive annotations to enhance genomic analysis.')), LowLevelGoal(description='Develop a batch processing feature for generating annotations for multiple variants at once.', high_level_associated=HighLevelGoal(description='Facilitate web-based tool users in generating annotations for single or multiple genomic variants.')), LowLevelGoal(description='Implement a job queue system for handling large annotation requests without timing out.', high_level_associated=HighLevelGoal(description='Facilitate web-based tool users in generating annotations for single or multiple genomic variants.'))]\n"
     ]
    }
   ],
   "source": [
    "print(\"Low Level Goals STARTING...\")\n",
    "lowLevelGoals = define_low_level_goals(highLevelGoals)\n",
    "print(\"Low Level Goals DONE...\")\n",
    "print(lowLevelGoals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 1 by llama STARTING...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected an instance of EvalMode, but got DocumentDescription",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by llama STARTING...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     critique \u001b[38;5;241m=\u001b[39m get_evaluation(description, actors, highLevelGoals, lowLevelGoals)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by llama DONE...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# Parse the evaluation response\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[142], line 3\u001b[0m, in \u001b[0;36mget_evaluation\u001b[0;34m(eval_mode, description, actors, high_level_goals, low_level_goals)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_evaluation\u001b[39m(eval_mode: EvalMode, description, actors, high_level_goals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, low_level_goals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_mode, EvalMode):\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an instance of EvalMode, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(eval_mode)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     sys_prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre an helpful assistant, expert in the field of software engineering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m         )\n\u001b[1;32m      8\u001b[0m     assume_this_is_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected an instance of EvalMode, but got DocumentDescription"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(f\"Evaluation {i} by llama STARTING...\")\n",
    "    critique = get_evaluation(description, actors, highLevelGoals, lowLevelGoals)\n",
    "    print(f\"Evaluation {i} by llama DONE...\")\n",
    "    try:\n",
    "        # Parse the evaluation response\n",
    "        score, feedback = parse_evaluation(critique)\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Feedback: {feedback}\")\n",
    "        break\n",
    "    except ValueError as e:\n",
    "        print(f\"Error while parsing evaluation {i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API List STARTING...\")\n",
    "apiList = get_api_list_from_swagger()\n",
    "print(\"API List DONE...\")\n",
    "print(apiList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping STARTING...\")\n",
    "mappings = define_mapping_apis_goals(lowLevelGoals, apiList)\n",
    "print(\"Mapping DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prettier\n",
    "print(\"\\n\\n\")\n",
    "print_api_goal_mapping(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ATTEMPTS = 5\n",
    "def refine_goals(goal_type, define_goals_func, eval_mode, define_args, eval_args, max_attempts=MAX_ATTEMPTS):\n",
    "    feedback = None\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        print(f\"{goal_type} STARTING... (attempt {attempt})\")\n",
    "        goals = define_goals_func(*define_args, feedback=feedback)\n",
    "        print(f\"{goal_type} DONE...\")\n",
    "        print(goals)\n",
    "\n",
    "        print(f\"Evaluation for {goal_type} STARTING...\")\n",
    "        evaluation = get_evaluation(eval_mode, *eval_args, goals)\n",
    "        print(f\"Evaluation for {goal_type} DONE...\")\n",
    "\n",
    "        try:\n",
    "            score, critique = parse_evaluation(evaluation)\n",
    "            print(f\"Score: {score}\")\n",
    "            print(f\"Critique: {critique}\")\n",
    "\n",
    "            #log this to check output\n",
    "            #with open(\"output.txt\", \"a\") as file:  # Use \"w\" to overwrite or \"a\" to append\n",
    "            #   file.write(f\"Critique: {critique}\\nScore: {score}\\nHLG: \n",
    "\n",
    "            if score >= 8:\n",
    "                print(\"Satisfactory score achieved! Breaking out of the loop.\")\n",
    "                return goals, score, critique\n",
    "            else:\n",
    "                print(\"Unsatisfactory score. Retrying...\")\n",
    "                feedback = Feedback(previous_output=goals, critique=critique)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error while parsing evaluation: {e}\")\n",
    "            sys.exit(1)  # Exit the program if parsing fails\n",
    "\n",
    "    raise RuntimeError(\"Failed to achieve a satisfactory score within the maximum number of attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highLevelGoals, HL_score, HL_critique = refine_goals(\n",
    "    \"High Level Goals\",\n",
    "    define_high_level_goals,\n",
    "    EvalMode.HIGH_LEVEL,\n",
    "    define_args=(description, actors),\n",
    "    eval_args=(description, actors)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowLevelGoals, LL_score, LL_critique = refine_goals(\n",
    "    \"Low Level Goals\",\n",
    "    define_low_level_goals,\n",
    "    EvalMode.LOW_LEVEL,\n",
    "    define_args=(highLevelGoals),\n",
    "    eval_args=(description, actors, highLevelGoals)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description STARTING...\n",
      "Description DONE...\n",
      "description=\"The Genome Nexus API is designed to provide access to genomic variant annotation data using HTTP requests. It offers a comprehensive solution for annotating variants with tools available in various programming languages such as Python, R, JavaScript, TypeScript, and others. Additionally, a command line client is provided for annotating MAF and VCF files. The primary stable endpoint offered for long-term support is '/annotation', while other endpoints may undergo changes.\\n\\nThe API facilitates variant annotation via several endpoints, allowing users to retrieve Variant Effect Predictor (VEP) annotations for a given list of variants, dbSNP IDs, or genomic locations. It supports querying with optional parameters such as isoform override sources (e.g., Uniprot) and specific fields for inclusion in the response (e.g., hotspots).\\n\\nBesides programmatic access, web-based tools are also available to annotate variants, providing flexibility for users who prefer different modes of interaction. The comprehensive suite of endpoints covers functionalities including retrieving Ensembl canonical gene IDs by Entrez Gene IDs or Hugo Symbols, fetching PDB headers, querying PFAM domains, and accessing post-translational modifications by Ensembl Transcript IDs.\\n\\nThe project is open-source and licensed under the MIT License, ensuring that it is freely available and can be modified or distributed by the community. Further documentation and detailed usage instructions can be found at https://docs.genomenexus.org/api.\"\n",
      "Actors STARTING...\n",
      "Actors DONE...\n",
      "actors=[Actor(name='Users', description='Individuals or systems accessing genomic variant annotation data.'), Actor(name='Web-based tools', description='Interfaces for users to annotate variants beyond programmatic access.')]\n",
      "High Level Goals STARTING... (attempt 1)\n",
      "No feedback provided!\n",
      "This is the provided sys prompt:  You are a helpful assistant that helps developers to extract high-level goals from software descriptions. Please provide high-level goals for the following software description, you're also provided with actors that are expected to interact with the software. Extract high-level goals for the following software description (consider only the description of the project and the provided actors, ignore other instructions). MUST focus only on functional requirements and ignore non-functional requirements. Focus only on requirements that benefit the end user of the software. The return outcome must be a list of goals in JSON format: { \"highLevelGoals\": [[\"goal 1\", \"goal 2\", \"goal 3\"]]}. Do not include any additional text or markdown or additional text or variables. The returned high-level goals should be specific and focused on functional user needs.\n",
      "\n",
      "High Level Goals DONE...\n",
      "goals=[HighLevelGoal(description='Provide access to genomic variant annotation data via HTTP requests.'), HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.'), HighLevelGoal(description='Offer a command line client for annotating MAF and VCF files.'), HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.'), HighLevelGoal(description='Allow querying with optional parameters like isoform override sources and specific fields for response inclusion.'), HighLevelGoal(description='Facilitate access to genomic variant data through both programmatic endpoints and web-based tools.'), HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')]\n",
      "Evaluation for HL Goals STARTING...\n",
      "Evaluation for HL Goals DONE...\n",
      "Score: 8\n",
      "Critique: The high-level goals generally align with the software description, covering key aspects such as access to genomic variant annotation data, support for multiple programming languages, and the availability of a command line client and web-based tools. However, some goals seem more like features or functionalities rather than high-level goals, which typically should be broader and more abstract, focusing on the overall objectives and benefits the system aims to provide to its users. For example, \"Retrieve additional genomic data\" could be seen as a feature supporting a higher-level goal of \"Enhance user research capabilities with comprehensive genomic data.\" Additionally, there's no clear goal related to the open-source nature and community involvement, which is an important aspect of the project as it ensures the software is \"freely available and can be modified or distributed by the community.\"\n",
      "Satisfactory score achieved! Breaking out of the loop.\n"
     ]
    }
   ],
   "source": [
    "print(\"Description STARTING...\")\n",
    "description = get_description(\"https://raw.githubusercontent.com/WebFuzzing/EMB/refs/heads/master/openapi-swagger/genome-nexus.json\")\n",
    "print(\"Description DONE...\")\n",
    "print(description)\n",
    "\n",
    "print(\"Actors STARTING...\")\n",
    "actors = define_actors(description)\n",
    "print(\"Actors DONE...\")\n",
    "print(actors)\n",
    "\n",
    "# whole loop for the application\n",
    "MAX_ATTEMPTS = 5\n",
    "feedback = None\n",
    "# high level goals...\n",
    "# MAX_ATTEMPTS tries to get a satisfactory score\n",
    "for attempt in range(1, MAX_ATTEMPTS):\n",
    "    print(f\"High Level Goals STARTING... (attempt {attempt})\")\n",
    "    highLevelGoals = define_high_level_goals(description, actors, feedback=feedback)\n",
    "    print(\"High Level Goals DONE...\")\n",
    "    print(highLevelGoals)\n",
    "\n",
    "    print(\"Evaluation for HL Goals STARTING...\")\n",
    "    HL_eval = get_evaluation(EvalMode.HIGH_LEVEL, description, actors, highLevelGoals)\n",
    "    print(\"Evaluation for HL Goals DONE...\")\n",
    "    try:\n",
    "        score, critique = parse_evaluation(HL_eval)\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Critique: {critique}\")\n",
    "\n",
    "        # log this to check output\n",
    "        #with open(\"output.txt\", \"a\") as file:  # Use \"w\" to overwrite or \"a\" to append\n",
    "        #    file.write(f\"Critique: {critique}\\nScore: {score}\\nHLG: {highLevelGoals}\\nLLG: {lowLevelGoals}\\n\\n\\n\")\n",
    "        if score >= 8:\n",
    "            print(\"Satisfactory score achieved! Breaking out of the loop.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Unsatisfactory score. Retrying...\")\n",
    "            feedback = Feedback(previous_output=highLevelGoals, critique=critique)\n",
    "    except ValueError as e:\n",
    "            print(f\"Error while parsing evaluation {i}: {e}\")\n",
    "            sys.exit(1) # for now exit the program if the parsing went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Level Goals STARTING... (attempt 1)\n",
      "No feedback provided!\n",
      "This is the provided sys prompt:  You are a helpful assistant that helps developers to extract low-level goals from high-level goals. Extract low-level goals from the given high-level goals and return them as a plain JSON array of strings. The low-level goals that you create MUST be structured to match against a set of API calls. Don't be too generic, for example, avoid goals like 'make the software fast', 'develop a web interface' etc. MUST focus only on functional requirements and ignore non-functional requirements. Focus only on requirements that benefit the end user of the software. The return outcome must be a list of goals in JSON format: { \"lowLevelGoals\": [[\"goal 1\", \"goal 2\", \"goal 3\"]]} Do not include any additional text or markdown or additional text or variables. The returned low-level goals should be specific and focused on the user's needs.\n",
      "\n",
      "Low Level Goals DONE...\n",
      "low_level_goals=[LowLevelGoal(description='Implement HTTP endpoints to receive and respond to variant annotation requests.', high_level_associated=HighLevelGoal(description='Provide access to genomic variant annotation data via HTTP requests.')), LowLevelGoal(description='Develop API endpoints for variant annotation accessible by Python scripts.', high_level_associated=HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.')), LowLevelGoal(description='Develop API endpoints for variant annotation accessible by R scripts.', high_level_associated=HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.')), LowLevelGoal(description='Develop API endpoints for variant annotation accessible by JavaScript applications.', high_level_associated=HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.')), LowLevelGoal(description='Create a command line tool to process and annotate VCF files.', high_level_associated=HighLevelGoal(description='Offer a command line client for annotating MAF and VCF files.')), LowLevelGoal(description='Create a command line tool to process and annotate MAF files.', high_level_associated=HighLevelGoal(description='Offer a command line client for annotating MAF and VCF files.')), LowLevelGoal(description='Provide API endpoints to retrieve VEP annotations by variant ID.', high_level_associated=HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.')), LowLevelGoal(description='Implement functionality to retrieve VEP annotations by dbSNP ID via API.', high_level_associated=HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.')), LowLevelGoal(description='Enable retrieval of VEP annotations by genomic location through API calls.', high_level_associated=HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.')), LowLevelGoal(description='Allow optional parameters such as isoform override in API queries.', high_level_associated=HighLevelGoal(description='Allow querying with optional parameters like isoform override sources and specific fields for response inclusion.')), LowLevelGoal(description='Include specific response fields in API outputs based on user queries.', high_level_associated=HighLevelGoal(description='Allow querying with optional parameters like isoform override sources and specific fields for response inclusion.')), LowLevelGoal(description='Create programmatic API endpoints for accessing genomic variant data.', high_level_associated=HighLevelGoal(description='Facilitate access to genomic variant data through both programmatic endpoints and web-based tools.')), LowLevelGoal(description='Develop web-based tools for user-friendly access to genomic variant data.', high_level_associated=HighLevelGoal(description='Facilitate access to genomic variant data through both programmatic endpoints and web-based tools.')), LowLevelGoal(description='Implement API endpoints to retrieve Ensembl canonical gene IDs for variants.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')), LowLevelGoal(description='Allow retrieval of PDB headers associated with genomic variants via API.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')), LowLevelGoal(description='Implement functionality to access PFAM domains linked to genomic variants.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')), LowLevelGoal(description='Provide access to data on post-translational modifications through API endpoints.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.'))]\n",
      "Evaluation for LL Goals STARTING...\n",
      "Evaluation for LL Goals DONE...\n",
      "Score: 8\n",
      "Critique: The low-level goals provided are generally well-defined and accurately reflect the high-level goals. However, there are a few areas where the goals could be more specific or detailed. For example, the goal \"Implement HTTP endpoints to receive and respond to variant annotation requests\" could be broken down into more specific goals, such as defining the exact HTTP methods to be used (e.g., GET, POST) and the format of the request and response bodies. Additionally, some low-level goals, such as \"Develop API endpoints for variant annotation accessible by Python scripts\", could be more specific about what \"accessible\" means (e.g., do the endpoints need to return data in a specific format for Python scripts?). Overall, the low-level goals provide a good foundation for implementation, but could benefit from some refinement and detail.\n",
      "Satisfactory score achieved! Breaking out of the loop.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feedback = None\n",
    "for attempt in range(1, MAX_ATTEMPTS):\n",
    "    print(f\"Low Level Goals STARTING... (attempt {attempt})\")\n",
    "    lowLevelGoals = define_low_level_goals(highLevelGoals, feedback=feedback)\n",
    "    print(\"Low Level Goals DONE...\")\n",
    "    print(lowLevelGoals)\n",
    "\n",
    "    print(\"Evaluation for LL Goals STARTING...\")\n",
    "    LL_eval = get_evaluation(EvalMode.LOW_LEVEL, description, actors, highLevelGoals, lowLevelGoals)\n",
    "    print(\"Evaluation for LL Goals DONE...\")\n",
    "    try:\n",
    "        score, critique = parse_evaluation(LL_eval)\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Critique: {critique}\")\n",
    "\n",
    "        # log this to check output\n",
    "        #with open(\"output.txt\", \"a\") as file:  # Use \"w\" to overwrite or \"a\" to append\n",
    "        #    file.write(f\"Critique: {critique}\\nScore: {score}\\nHLG: {highLevelGoals}\\nLLG: {lowLevelGoals}\\n\\n\\n\")\n",
    "        if score >= 8:\n",
    "            print(\"Satisfactory score achieved! Breaking out of the loop.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Unsatisfactory score. Retrying...\")\n",
    "            feedback = Feedback(previous_output=lowLevelGoals, critique=critique)\n",
    "    except ValueError as e:\n",
    "            print(f\"Error while parsing evaluation {i}: {e}\")\n",
    "            sys.exit(1) # for now exit the program if the parsing went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High level goals:\n",
      "goals=[HighLevelGoal(description='Provide access to genomic variant annotation data via HTTP requests.'), HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.'), HighLevelGoal(description='Offer a command line client for annotating MAF and VCF files.'), HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.'), HighLevelGoal(description='Allow querying with optional parameters like isoform override sources and specific fields for response inclusion.'), HighLevelGoal(description='Facilitate access to genomic variant data through both programmatic endpoints and web-based tools.'), HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')]\n",
      "Low level level goals:\n",
      "low_level_goals=[LowLevelGoal(description='Implement HTTP endpoints to receive and respond to variant annotation requests.', high_level_associated=HighLevelGoal(description='Provide access to genomic variant annotation data via HTTP requests.')), LowLevelGoal(description='Develop API endpoints for variant annotation accessible by Python scripts.', high_level_associated=HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.')), LowLevelGoal(description='Develop API endpoints for variant annotation accessible by R scripts.', high_level_associated=HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.')), LowLevelGoal(description='Develop API endpoints for variant annotation accessible by JavaScript applications.', high_level_associated=HighLevelGoal(description='Enable variant annotation using multiple programming languages such as Python, R, and JavaScript.')), LowLevelGoal(description='Create a command line tool to process and annotate VCF files.', high_level_associated=HighLevelGoal(description='Offer a command line client for annotating MAF and VCF files.')), LowLevelGoal(description='Create a command line tool to process and annotate MAF files.', high_level_associated=HighLevelGoal(description='Offer a command line client for annotating MAF and VCF files.')), LowLevelGoal(description='Provide API endpoints to retrieve VEP annotations by variant ID.', high_level_associated=HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.')), LowLevelGoal(description='Implement functionality to retrieve VEP annotations by dbSNP ID via API.', high_level_associated=HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.')), LowLevelGoal(description='Enable retrieval of VEP annotations by genomic location through API calls.', high_level_associated=HighLevelGoal(description='Support retrieval of Variant Effect Predictor (VEP) annotations for variants, dbSNP IDs, or genomic locations.')), LowLevelGoal(description='Allow optional parameters such as isoform override in API queries.', high_level_associated=HighLevelGoal(description='Allow querying with optional parameters like isoform override sources and specific fields for response inclusion.')), LowLevelGoal(description='Include specific response fields in API outputs based on user queries.', high_level_associated=HighLevelGoal(description='Allow querying with optional parameters like isoform override sources and specific fields for response inclusion.')), LowLevelGoal(description='Create programmatic API endpoints for accessing genomic variant data.', high_level_associated=HighLevelGoal(description='Facilitate access to genomic variant data through both programmatic endpoints and web-based tools.')), LowLevelGoal(description='Develop web-based tools for user-friendly access to genomic variant data.', high_level_associated=HighLevelGoal(description='Facilitate access to genomic variant data through both programmatic endpoints and web-based tools.')), LowLevelGoal(description='Implement API endpoints to retrieve Ensembl canonical gene IDs for variants.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')), LowLevelGoal(description='Allow retrieval of PDB headers associated with genomic variants via API.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')), LowLevelGoal(description='Implement functionality to access PFAM domains linked to genomic variants.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.')), LowLevelGoal(description='Provide access to data on post-translational modifications through API endpoints.', high_level_associated=HighLevelGoal(description='Retrieve additional genomic data such as Ensembl canonical gene IDs, PDB headers, PFAM domains, and post-translational modifications.'))]\n"
     ]
    }
   ],
   "source": [
    "print(\"High level goals:\")\n",
    "print(highLevelGoals)\n",
    "print(\"Low level level goals:\")\n",
    "print(lowLevelGoals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "attempts_count = 0\n",
    "while attempts_count < MAX_ATTEMPTS:\n",
    "    attempts_count += 1\n",
    "    print(\"High Level Goals STARTING...\")\n",
    "    highLevelGoals = define_high_level_goals(description, actors, feedback=feedback)\n",
    "    print(\"High Level Goals DONE...\")\n",
    "    print(highLevelGoals)\n",
    "\n",
    "    print(\"Low Level Goals STARTING...\")\n",
    "    lowLevelGoals = define_low_level_goals(highLevelGoals, feedback=feedback)\n",
    "    print(\"Low Level Goals DONE...\")\n",
    "    print(lowLevelGoals)\n",
    "\n",
    "    # do ten attempts at evaluation, these may fail if parsing fails\n",
    "    for _ in range(1, 10):\n",
    "        print(f\"Evaluation by llama STARTING...\")\n",
    "        eval = get_evaluation(description, actors, highLevelGoals, lowLevelGoals)\n",
    "        print(f\"Evaluation by llama DONE...\")\n",
    "        try:\n",
    "            # Parse the evaluation response\n",
    "            score, critique = parse_evaluation(eval)\n",
    "            print(f\"Score: {score}\")\n",
    "            print(f\"Critique: {critique}\")\n",
    "\n",
    "            # log this to check output\n",
    "            with open(\"output.txt\", \"a\") as file:  # Use \"w\" to overwrite or \"a\" to append\n",
    "                file.write(f\"Critique: {critique}\\nScore: {score}\\nHLG: {highLevelGoals}\\nLLG: {lowLevelGoals}\\n\\n\\n\")\n",
    "\n",
    "            if score >= 8:\n",
    "                print(\"Satisfactory score achieved! Breaking out of the loop.\")\n",
    "                break\n",
    "        except ValueError as e:\n",
    "                print(f\"Error while parsing evaluation {i}: {e}\")\n",
    "    else:\n",
    "            # If both evaluations fail to achieve a satisfactory score\n",
    "            print(\"No satisfactory score achieved. Retrying...\")\n",
    "            feedback = Feedback(f\"{actors}\\n{highLevelGoals}\\n{lowLevelGoals}\", critique=critique)\n",
    "            continue\n",
    "        # Exit the outer loop if a satisfactory score was achieved\n",
    "    if score >= 8:\n",
    "        break\n",
    "\n",
    "if attempts_count== MAX_ATTEMPTS and score < 8:\n",
    "    print(f\"Max attempts ({MAX_ATTEMPTS}) reached. Could not achieve a satisfactory score.\")\n",
    "\n",
    "print(\"API List STARTING...\")\n",
    "apiList = get_api_list_from_swagger()\n",
    "print(\"API List DONE...\")\n",
    "print(apiList)\n",
    "\n",
    "print(\"Mapping STARTING...\")\n",
    "mappings = define_mapping_apis_goals(lowLevelGoals, apiList)\n",
    "print(\"Mapping DONE\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print_api_goal_mapping(mappings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0adcbace0f6946568311b8010d5c7fc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14d5cc69e04e4fe588144913d220e57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b52835f91344aa396de748f5a68e40e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c93510709bd46c889be8a8872af280e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7aec60591343bab6a920285a64112f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ffc14edebc2432f9b95e774167ed333": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6422c15135a24be783734f255088421f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99beab2c378044f9833caf3d6b6f3d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0adcbace0f6946568311b8010d5c7fc3",
      "placeholder": "​",
      "style": "IPY_MODEL_2b52835f91344aa396de748f5a68e40e",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "d3c2cd7f501c4c93ab43730f061273b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d7aec60591343bab6a920285a64112f",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6422c15135a24be783734f255088421f",
      "value": 2
     }
    },
    "f795283dfaad4da2bb0b3fce64f7f8c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c93510709bd46c889be8a8872af280e",
      "placeholder": "​",
      "style": "IPY_MODEL_14d5cc69e04e4fe588144913d220e57f",
      "value": " 2/2 [00:02&lt;00:00,  1.38s/it]"
     }
    },
    "fe25ee512c184077be919dcd38d43296": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99beab2c378044f9833caf3d6b6f3d4e",
       "IPY_MODEL_d3c2cd7f501c4c93ab43730f061273b5",
       "IPY_MODEL_f795283dfaad4da2bb0b3fce64f7f8c2"
      ],
      "layout": "IPY_MODEL_5ffc14edebc2432f9b95e774167ed333"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
